{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9cecee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "# Path to the vectorstore relative to this notebook\n",
    "FAISS_DB_PATH = os.path.abspath(os.path.join(\"..\", \"her2_faiss_db\"))\n",
    "\n",
    "# Load FAISS vectorstore\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "vectorstore = FAISS.load_local(FAISS_DB_PATH, embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "# Load Flan-T5 model\n",
    "model_id = \"google/flan-t5-large\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_id)\n",
    "llm_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "858341bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(context: str, question: str) -> str:\n",
    "    return f\"\"\"You are a biomedical research assistant. Read the context and answer the question in a detailed, informative way suitable for a graduate-level researcher.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "def get_answer(query: str) -> str:\n",
    "    docs = vectorstore.similarity_search(query, k=10)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "    prompt = build_prompt(context, query)\n",
    "    result = llm_pipeline(prompt, max_new_tokens=512, temperature=0.2)\n",
    "    return result[0][\"generated_text\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c95ff1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/qa/her2_qa_dataset.json\") as f:\n",
    "    qa_dataset = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dfcdc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answering: What gene is associated with poor prognosis in human breast cancer?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1221 > 512). Running this sequence through the model will result in indexing errors\n",
      "/home/zlc/miniconda3/envs/rag-chatbot/lib/python3.10/site-packages/transformers/generation/configuration_utils.py:628: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.2` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answering: In how many of the 103 tumors was HER-2/neu gene amplification found in the initial study?\n",
      "Answering: Does HER-2/neu amplification correlate with hormone receptor status?\n",
      "Answering: How does HER-2/neu amplification affect relapse and survival rates?\n",
      "Answering: What statistical test was used to compare survival curves?\n",
      "Answering: How many patients had HER-2/neu amplification in the second group of 86 node-positive samples?\n",
      "Answering: Is HER-2/neu amplification an independent prognostic factor?\n",
      "Answering: What was the median follow-up time in the node-positive patient study?\n",
      "Answering: What methods were used to detect HER-2/neu amplification?\n",
      "Answering: Which other gene was compared with HER-2/neu for amplification?\n"
     ]
    }
   ],
   "source": [
    "chatbot_predictions = {}\n",
    "\n",
    "for qa in qa_dataset:\n",
    "    qid = qa[\"id\"]\n",
    "    question = qa[\"question\"]\n",
    "    print(f\"Answering: {question}\")\n",
    "    answer = get_answer(question)\n",
    "    chatbot_predictions[qid] = answer\n",
    "\n",
    "with open(\"../data/qa/her2_predictions.json\", \"w\") as f:\n",
    "    json.dump(chatbot_predictions, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e6792727",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/qa/her2_predictions.json\", \"w\") as f:\n",
    "    json.dump(chatbot_predictions, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86843eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>F1 Score per Question (⚠️ = Flagged as Weak)</h3>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Gold Answer</th>\n",
       "      <th>Predicted Answer</th>\n",
       "      <th>F1 Score</th>\n",
       "      <th>Flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What gene is associated with poor prognosis in...</td>\n",
       "      <td>HER-2/neu gene amplification is associated wit...</td>\n",
       "      <td>HER-2/neu</td>\n",
       "      <td>0.15</td>\n",
       "      <td>⚠️ Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>In how many of the 103 tumors was HER-2/neu ge...</td>\n",
       "      <td>In 19 out of 103 tumors (18%).</td>\n",
       "      <td>34/86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>⚠️ Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Does HER-2/neu amplification correlate with ho...</td>\n",
       "      <td>No significant correlation was found between H...</td>\n",
       "      <td>The presence of gene amplification was correla...</td>\n",
       "      <td>0.39</td>\n",
       "      <td>⚠️ Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How does HER-2/neu amplification affect relaps...</td>\n",
       "      <td>Amplification significantly correlates with sh...</td>\n",
       "      <td>While there was a somewhat shortened time to r...</td>\n",
       "      <td>0.37</td>\n",
       "      <td>⚠️ Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What statistical test was used to compare surv...</td>\n",
       "      <td>The log-rank test was used to compare Kaplan-M...</td>\n",
       "      <td>log rank test</td>\n",
       "      <td>0.17</td>\n",
       "      <td>⚠️ Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How many patients had HER-2/neu amplification ...</td>\n",
       "      <td>34 out of 86 node-positive patients had HER-2/...</td>\n",
       "      <td>34/86</td>\n",
       "      <td>0.00</td>\n",
       "      <td>⚠️ Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Is HER-2/neu amplification an independent prog...</td>\n",
       "      <td>Yes, multivariate analysis showed HER-2/neu am...</td>\n",
       "      <td>Amplification of the HER-2/neu gene is a signi...</td>\n",
       "      <td>0.13</td>\n",
       "      <td>⚠️ Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>What was the median follow-up time in the node...</td>\n",
       "      <td>The median follow-up time was 46 months.</td>\n",
       "      <td>47 months</td>\n",
       "      <td>0.25</td>\n",
       "      <td>⚠️ Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What methods were used to detect HER-2/neu amp...</td>\n",
       "      <td>Southern blot analysis with a 32P-labeled HER-...</td>\n",
       "      <td>x2 test. P values werc computed after combinin...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>⚠️ Weak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Which other gene was compared with HER-2/neu f...</td>\n",
       "      <td>The EGFR gene was compared, and found to be am...</td>\n",
       "      <td>N-myc</td>\n",
       "      <td>0.00</td>\n",
       "      <td>⚠️ Weak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  What gene is associated with poor prognosis in...   \n",
       "1  In how many of the 103 tumors was HER-2/neu ge...   \n",
       "2  Does HER-2/neu amplification correlate with ho...   \n",
       "3  How does HER-2/neu amplification affect relaps...   \n",
       "4  What statistical test was used to compare surv...   \n",
       "5  How many patients had HER-2/neu amplification ...   \n",
       "6  Is HER-2/neu amplification an independent prog...   \n",
       "7  What was the median follow-up time in the node...   \n",
       "8  What methods were used to detect HER-2/neu amp...   \n",
       "9  Which other gene was compared with HER-2/neu f...   \n",
       "\n",
       "                                         Gold Answer  \\\n",
       "0  HER-2/neu gene amplification is associated wit...   \n",
       "1                     In 19 out of 103 tumors (18%).   \n",
       "2  No significant correlation was found between H...   \n",
       "3  Amplification significantly correlates with sh...   \n",
       "4  The log-rank test was used to compare Kaplan-M...   \n",
       "5  34 out of 86 node-positive patients had HER-2/...   \n",
       "6  Yes, multivariate analysis showed HER-2/neu am...   \n",
       "7           The median follow-up time was 46 months.   \n",
       "8  Southern blot analysis with a 32P-labeled HER-...   \n",
       "9  The EGFR gene was compared, and found to be am...   \n",
       "\n",
       "                                    Predicted Answer  F1 Score     Flag  \n",
       "0                                          HER-2/neu      0.15  ⚠️ Weak  \n",
       "1                                              34/86      0.00  ⚠️ Weak  \n",
       "2  The presence of gene amplification was correla...      0.39  ⚠️ Weak  \n",
       "3  While there was a somewhat shortened time to r...      0.37  ⚠️ Weak  \n",
       "4                                      log rank test      0.17  ⚠️ Weak  \n",
       "5                                              34/86      0.00  ⚠️ Weak  \n",
       "6  Amplification of the HER-2/neu gene is a signi...      0.13  ⚠️ Weak  \n",
       "7                                          47 months      0.25  ⚠️ Weak  \n",
       "8  x2 test. P values werc computed after combinin...      0.09  ⚠️ Weak  \n",
       "9                                              N-myc      0.00  ⚠️ Weak  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'Average F1 Score (%)': np.float64(15.5)}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# --- F1-only evaluation functions ---\n",
    "def normalize_answer(s: str) -> str:\n",
    "    def remove_articles(text): return re.sub(r'\\b(a|an|the)\\b', ' ', text)\n",
    "    def white_space_fix(text): return ' '.join(text.split())\n",
    "    def remove_punc(text): return ''.join(ch for ch in text if ch not in set(string.punctuation))\n",
    "    def lower(text): return text.lower()\n",
    "    return white_space_fix(remove_articles(remove_punc(lower(s))))\n",
    "\n",
    "def compute_f1(a_gold: str, a_pred: str) -> float:\n",
    "    gold_tokens = normalize_answer(a_gold).split()\n",
    "    pred_tokens = normalize_answer(a_pred).split()\n",
    "    common = set(gold_tokens) & set(pred_tokens)\n",
    "    if not common: return 0.0\n",
    "    precision = len(common) / len(pred_tokens)\n",
    "    recall = len(common) / len(gold_tokens)\n",
    "    return 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# --- Build evaluation table ---\n",
    "records = []\n",
    "\n",
    "for qa in qa_dataset:\n",
    "    qid = qa[\"id\"]\n",
    "    question = qa[\"question\"]\n",
    "    gold = qa[\"answer\"]\n",
    "    pred = chatbot_predictions.get(qid, \"\")\n",
    "    f1 = compute_f1(gold, pred)\n",
    "    flag = \"⚠️ Weak\" if f1 < 0.5 else \"\"\n",
    "    \n",
    "    records.append({\n",
    "        \"Question\": question,\n",
    "        \"Gold Answer\": gold,\n",
    "        \"Predicted Answer\": pred,\n",
    "        \"F1 Score\": round(f1, 2),\n",
    "        \"Flag\": flag\n",
    "    })\n",
    "\n",
    "df_eval = pd.DataFrame(records)\n",
    "\n",
    "# --- Display ---\n",
    "display(HTML(\"<h3>F1 Score per Question (⚠️ = Flagged as Weak)</h3>\"))\n",
    "display(df_eval)\n",
    "\n",
    "# --- Also return average F1 score ---\n",
    "avg_f1 = df_eval[\"F1 Score\"].mean()\n",
    "{\"Average F1 Score (%)\": round(avg_f1 * 100, 2)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f81e9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-chatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
